<!DOCTYPE HTML>

<html>
	<head>
		<title>Aymane Page</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
					<div id="intro">
						<h1>Portfolio<br />
						</h1>
						<p>Aymane Moataz, phd student in machine learning.</p>
						<ul class="actions">
							<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
						</ul>
					</div>
				
				<!-- Main -->
				<div id="main">
					<!-- Posts -->
						<section class="posts">
							<article>
								<header>
									<h2><a href="https://github.com/moatazaymane/generative-adversarial-networks">Generative adversarial networks<br /></a></h2>
								</header>
								<a href="https://github.com/moatazaymane/generative-adversarial-networks" class="image fit"><img src="images/DCGAN - CelebA.png" alt="" /></a>
								<p>Generative adversarial networks first appeared in 2014, taking advantage of recent advances in computer vision at the time to build a generative model. The architecture of the model is composed of two different convolutional neural networks. A discriminator trained to classify images as true or false, and a generator that produces synthetic images. I used logarithmic loss to train both the discriminator and the generator. This involves updating the weights of the two networks in turn, with the discriminator trained to distinguish between real and fake images, while the generator's weights are updated so that the synthetic images produced fool the discriminator.</p>
								<ul class="actions special">
									<li><a href="https://github.com/moatazaymane/generative-adversarial-networks" class="button">Discover the project</a></li>
								</ul>
							</article>
						</section>
					<!-- Footer -->
				</div>

				<!-- Main -->
				<div id="main">
					<!-- Posts -->
						<section class="posts">
							<article>
								<header>
									<h2><a href="https://github.com/moatazaymane/image_reconstruction_attacks">Attribute reconstruction attacks<br /></a></h2>
								</header>
								<a href="https://github.com/moatazaymane/image_reconstruction_attacks"><img src="images/reconstruction.png " width=200 height=300 alt="" /></a>
								<p>Reconstructing training data images from black-box access to machine learning classification model</p>
								<ul class="actions special">
									<li><a href="https://github.com/moatazaymane/image_reconstruction_attacks" class="button">Discover the project</a></li>
								</ul>
							</article>
						</section>
					<!-- Footer -->
				</div>

				
				<!-- Main -->
				<div id="main">
					<!-- Posts -->
						<section class="posts">
							<article>
								<header>
									<h2><a href="https://github.com/moatazaymane/deep-dream">Deep Dream<br /></a></h2>
								</header>
								<a href="https://github.com/moatazaymane/deep-dream" class="image fit"><img src="images/vgg19_layer12.png" alt="" /></a>
								<p>Deep dream is a technique used to produce images that maximize the activations of selected layers in convolutional neural networks. The resulting image can be used to visualize the features learned by convolutional neural network. After choosing a layer, the image is gradually changed to maximize the activations. The deep dream technique was first introduced in 2015 by Google's Alexander Mordvintsev Inceptionism: Going Deeper into Neural Networks. It was used to better understand the features learned by convolutional neural networks. The observable effect is that generally, shallower layers tend to produce certain features in images such as (circles, lines ...) while deeper layers that see more of the image recognize higher-level features such as (eyes, faces ...).</p>
								<ul class="actions special">
									<li><a href="https://github.com/moatazaymane/deep-dream" class="button">Discover the project</a></li>
								</ul>
							</article>
						</section>
					<!-- Footer -->
				</div>


			</div>

			<!-- Main -->
			<div id="main">
				<!-- Posts -->
					<section class="posts">
						<article>
							<header>
								<h2><a href="https://github.com/moatazaymane/pytorch-vision-transformer">Original Vision Transformer<br /></a></h2>
							</header>
							<a href="https://github.com/moatazaymane/pytorch-vision-transformer" class="image fit"><img src="images/vision-transformer.png" alt=""/></a>
							<p>Building a vision transformer from scratch. Implementation of the paper "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</p>
							<ul class="actions special">
								<li><a href="https://github.com/moatazaymane/pytorch-vision-transformer" class="button">Discover the project</a></li>
							</ul>
						</article>
					</section>
				<!-- Footer -->
			</div>

			<!-- Main -->
			<div id="main">
				<!-- Posts -->
					<section class="posts">
						<article>
							<header>
								<h2><a href="https://github.com/moatazaymane/pytorch-transformer">Original Transformer<br /></a></h2>
							</header>
							<a href="https://github.com/moatazaymane/pytorch-transformer" class="image fit"><img src="images/Masked_Attention_Heatmap_4.png" alt=""/></a>
							<p>In this project I built an autoregressive language model. I trained the GPT 1 model on the opus books dataset. The objective is to predict the next token given the context</p>
							<ul class="actions special">
								<li><a href="https://github.com/moatazaymane/pytorch-transformer" class="button">Discover the project</a></li>
							</ul>
						</article>
					</section>
				<!-- Footer -->
			</div>


				<!-- Main -->
					<div id="main">
						<!-- Posts -->
							<section class="posts">
								<article>
									<header>
										<h2><a href="https://github.com/moatazaymane/Quora_Question_Pairs">Question Similarity<br />
										Prediction - NLP/ Deep Learning</a></h2>
									</header>
									<a href="https://github.com/moatazaymane/Quora_Question_Pairs" class="image fit"><img src="images/project_quora.png" alt="" /></a>
									<p>Quora is a social question-and-answer website, It's hardly surprising that many questions on Quora are similar in wording given that over 100 million people visit the site each month. The aim of the project is to detect similar question using supervised learning on a dataset of question pairs.</p>
									<ul class="actions special">
										<li><a href="https://github.com/moatazaymane/Quora_Question_Pairs" class="button">Discover the project</a></li>
									</ul>
								</article>
							</section>
						<!-- Footer -->
					</div>

				
			<!-- Footer -->
			<footer id="footer">
				<section class="split contact">
					<section class="alt">
						<h3>Address</h3>
						<p>Lille, 59000<br />
						France</p>
					</section>
					<section>
						<h3>Email</h3>
						<p><a href="mailto:moataz.aymane@gmail.com">moataz.aymane@gmail.com</a></p>
					</section>
					<section>
						<h3>Social</h3>
						<ul class="icons alt">
							<li><a href="https://www.linkedin.com/in/aymane-moataz/" class="icon brands alt fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://github.com/moatazaymane" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</section>
				</section>
			</footer>






		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>

